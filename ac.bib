@Article{Riegler2012,
  author   = {Alexander Riegler and Armin Scholl},
  journal  = {Constructivist Foundation},
  title    = {{L}uhmann and the sociological turn in constructivism},
  year     = {2012},
  number   = {1},
  pages    = {1--4},
  volume   = {8},
  file     = {:files/Riegler2012.pdf:PDF},
  keywords = {luhmann},
  url      = {http://constructivist.info/8/1/001},
}

@article{LeggHutter2007,
  author    = {Shane Legg and Marcus Hutter},
  title     = {Universal Intelligence: {A} Definition of Machine Intelligence},
  journal   = {Minds and Machines},
  year      = {2007},
  volume    = {17},
  number    = {4},
  pages     = {391--444},
  doi       = {10.1007/s11023-007-9079-x}
}

@book{Russell2019,
  author    = {Stuart Russell},
  title     = {Human Compatible: Artificial Intelligence and the Problem of Control},
  publisher = {Viking},
  year      = {2019},
  address   = {New York},
  isbn      = {978-0525558613}
}

@book{Hartmann1992,
  year = {1992},
  author = {Christian Hartmann},
  title = {{T}echnische {I}nteraktionskontexte. {A}spekte einer sozialwissenschaftlichen {T}heorie der {M}ensch-{C}omputer-{I}nteraktion},
  publisher = {Wiesbaden: Deutscher Universitäts-Verlag}
}

@misc{gabriel:2024,
  author       = {Markus Gabriel},
  title        = {{W}as ist eigentlich eine {K}{\"u}nstliche Intelligenz (KI)?},
  howpublished = {YouTube Video},
  year         = {2024},
  url          = {https://www.youtube.com/watch?v=jhJ1Wp4zemM},
  note         = {Vortrag, veröffentlicht auf YouTube}
}

@misc{gabriel:2025,
  author       = {Markus Gabriel},
  title        = {{P}hilosoph {M}arkus {G}abriel: {KI}, {G}ef{\"u}hle, {M}acht},
  howpublished = {YouTube Video},
  year         = {2025},
  url          = {https://www.youtube.com/watch?v=E1rfw2PR5MI},
  note         = {Vortrag, veröffentlicht auf YouTube}
}

@book{Brown1969,
  year = {1969},
  author = {Georg Spencer-Brown},
  title = {{L}aws of {F}orm},
  publisher = {London: Allen and Unwin}
}

@book{Foerster2013,
  url = {https://doi.org/10.1515/9780823255634},
  title = {The Beginning of Heaven and Earth Has No Name},
  title = {Seven Days with Second-Order Cybernetics},
  author = {Heinz von Foerster},
  editor = {Albert Müller and Karl H. Müller},
  publisher = {Fordham University Press},
  address = {New York, USA},
  doi = {10.1515/9780823255634},
  isbn = {9780823255634},
  year = {2013},
  lastchecked = {2025-02-10}
}

@Inbook{vonFoerster2003,
  author={von Foerster, Heinz},
  title={Cybernetics of Cybernetics},
  bookTitle={Understanding Understanding: Essays on Cybernetics and Cognition},
  year={2003},
  publisher={Springer New York},
  address={New York, NY},
  pages={283--286},
  isbn={978-0-387-21722-2},
  doi={10.1007/0-387-21722-3_13},
}

@book{Dreyfus1972,
  author = {Hubert L. Dreyfus},
  editor = {},
  publisher = {Harper \& Row},
  title = {What Computers Can't Do: The Limits of Artificial Intelligence},
  year = {1972}
}

@Inbook{Dreyfus1986,
  author={Dreyfus, Hubert L. and Dreyfus, Stuart E.},
  editor={Mitcham, Carl and Huning, Alois},
  title={From {S}ocrates to Expert Systems: The Limits of Calculative Rationality},
  bookTitle={Philosophy and Technology II: Information Technology and Computers in Theory and Practice},
  year={1986},
  publisher={Springer Netherlands},
  address={Dordrecht},
  pages={111--130},
  isbn={9789400945128},
  doi={10.1007/978-94-009-4512-8_9},
}

@article{zoennchen:2025,
  author={Z{\"o}nnchen, Benedikt and Dzhimova, Mariya and Socher, Gudrun},     
  title={From intelligence to autopoiesis: rethinking artificial intelligence through systems theory},
  journal={Frontiers in Communication},
  volume={Volume 10 - 2025},
  year={2025},
  doi={10.3389/fcomm.2025.1585321},
  issn={2297-900X},
  abstract={Hello this is a abstract},
  keywords={bzoennchen},
}

@Misc{Vaswani2017,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title         = {Attention is all you need},
  year          = {2017},
  archiveprefix = {arXiv},
  doi           = {10.48550/arXiv.1706.03762},
  eprint        = {1706.03762},
  file          = {:files/vaswani2017.pdf:PDF},
  keywords      = {transformer},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762},
}

@book{Luhmann2004,
  author = {Niklas Luhmann},
  publisher = {VS Verlag für Sozialwissenschaften},
  isbn = {978-3531428413},
  pages = {220},
  title = {{D}ie {R}ealität der {M}assenmedien},
  volume = {3},
  year = {2004}
}

@book{Luhmann1984,
  author = {Niklas Luhmann},
  publisher = {Suhrkamp Verlag},
  isbn = {978-3-518-28266-3},
  pages = {675},
  title = {{S}oziale {S}ysteme},
  volume = {8},
  year = {1984}
}

@book{Luhmann1998,
  author = {Niklas Luhmann},
  publisher = {Suhrkamp Verlag},
  isbn = {978-3-518-28960-0},
  pages = {1164},
  title = {Die {G}esellschaft der {G}esellschaft},
  year = {1998}
}

@book{Luhmann1992,
  author = {Niklas Luhmann},
  publisher = {Suhrkamp Verlag},
  isbn = {978-3-518-28601-2},
  pages = {1164},
  title = {Die {W}issenschaft der {G}esellschaft},
  year = {1992}
}

@article{Buchinger2012,
  author = {E. Buchinger},
  journal = {Constructivist Foundations},
  number = {1},
  pages = {19--28},
  title = {Luhmann and the constructivist heritage: A critical reflection},
  volume = {8},
  year = {2012}
}

@Inbook{Hessler2019,
  author = {Martina He{\ss}ler},
  bookTitle = {Autonome Systeme und Arbeit},
  publisher = {transcript Verlag},
  address = {Bielefeld},
  doi = {10.14361/9783839443958-010},
  isbn = {978-3-8394-4395-8},
  pages = {247--274},
  title = {{T}echnik und {A}utonomie},
  subtitle = {{K}ulturhistorische {B}emerkungen zu einem komplexen {V}erhältnis},
  year = {2019}
}

@book{vonGlasersfeld1995,
  address = {Washington, D.C.},
  author = {Ernst von Glasersfeld},
  editor = {},
  publisher = {Falmer Press},
  title = {Radical Constructivism: A Way of Knowing and Learning},
  year = {1995}
}

@book{Husserl1982,
  title = {Die {K}risis der europ{\"a}ischen {W}issenschaften und die transzendentale {P}hänomenologie},
  author = {Edmund Husserl},
  publisher = {Hamburg: Meiner},
  year = {1982},
}

@book{Husserl1993,
  url = {https://doi.org/10.1515/9783110916089},
  title = {{L}ogische {U}ntersuchungen},
  author = {Edmund Husserl},
  publisher = {De Gruyter},
  address = {Berlin, Boston},
  doi = {10.1515/9783110916089},
  isbn = {9783110916089},
  year = {1993},
  lastchecked = {2025-02-13}
}

@book{Husserl2002,
  url = {https://doi.org/10.1515/9783110916096},
  title = {{I}deen zu einer reinen {P}hänomenologie und phänomenologischen {P}hilosophie},
  subtitle = {{A}llgemeine {E}inführung in die reine {P}hänomenologie},
  author = {Edmund Husserl},
  publisher = {De Gruyter},
  address = {Berlin, Boston},
  doi = {10.1515/9783110916096},
  isbn = {9783110916096},
  year = {2002},
  lastchecked = {2025-01-21}
}

@book{Dignum2019,
  author   = {Virginia Dignum},
  subtitle  = {How to Develop and Use AI in a Responsible Way},
  title    = {Responsible Artificial Intelligence},
  year     = {2019},
  publisher = {Springer Cham},
  doi = {10.1007/978-3-030-30371-6},
  isbn = {978-3-030-30370-9},
}

@misc{Piantadosi2024,
  author       = {Steven T. Piantadosi},
  title        = {Modern language models refute {C}homsky's approach to language},
  month        = {jul},
  year         = {2024},
  publisher    = {Language Science Press},
  doi          = {10.5281/zenodo.12665933},
  url          = {https://doi.org/10.5281/zenodo.12665933},
}

@misc{Frege1892,
  author = {Friedrich Ludwig Gottlob Frege},
  title = {{\"U}ber {S}inn und {B}edeutung},
  year = {1892},
} 

@book{Agrawal2018,
  author = {Agrawal, Ajay and Gans, Joshua and Goldfarb, Avi},
  title = {Prediction Machines: The Simple Economics of Artificial Intelligence},
  year = {2018},
  isbn = {1633695670},
  publisher = {Harvard Business Review Press},
  address = {Boston, MA, USA},
  abstract = {}
  }

@book{Bostrom2016,
  title = {Superintelligence: Paths, Dangers, Strategies},
  author = {Nick Bostrom},
  year = {2016},
  isbn = {978–0–19–967811–2},
  publisher = {Oxford University Press},
}

@book{Floridi2011,
    author = {Floridi, Luciano},
    title = {The Philosophy of Information},
    publisher = {Oxford University Press},
    year = {2011},
    month = {01},
    abstract = {},
    isbn = {9780199232383},
    doi = {10.1093/acprof:oso/9780199232383.001.0001},
    url = {https://doi.org/10.1093/acprof:oso/9780199232383.001.0001},
}

@incollection{Hemmo2023,
  author = {Meir Hemmo and Orly Shenker},
  booktitle = {Mathematical Knowledge, Objects and Applications: Essays in Memory of Mark Steiner},
  editor = {Carl Posy and Yemima Ben{-}Menahem},
  pages = {263--300},
  publisher = {Springer},
  title = {Observer Dependent Physicalism: A New Argument for Reductive Physicalism and for Scientific Realism},
  year = {2023}
}

@book{Fodor1981,
  address = {Cambridge},
  author = {Jerry A. Fodor},
  editor = {},
  publisher = {MIT Press},
  title = {Representations: Philosophical Essays on the Foundations of Cognitive Science},
  year = {1981}
}

@book{Fodor1980,
  author = {Jerry A. Fodor},
  editor = {},
  publisher = {Harvard University Press},
  title = {The Language of Thought},
  year = {1980},
  isbn = {9780674510302}
}

@InCollection{Howard2023,
  author       =  {Robinson, Howard},
  title        =  {Dualism},
  booktitle    =  {The {Stanford} Encyclopedia of Philosophy},
  editor       =  {Edward N. Zalta and Uri Nodelman},
  howpublished =  {\url{https://plato.stanford.edu/archives/spr2023/entries/dualism/}},
  year         =  {2023},
  edition      =  {{S}pring 2023},
  publisher    =  {Metaphysics Research Lab, Stanford University}
}

@incollection{Block1996,
  author = {Ned Block},
  booktitle = {Routledge Encyclopedia of Philosophy: Genealogy to Iqbal},
  editor = {Edward Craig},
  pages = {242--256},
  publisher = {Routledge},
  title = {Conceptual role semantics},
  year = {1996}
}

@book{Mainzer2019,
  title = {{K}ünstliche {I}ntelligenz},
  subtitle = {{W}ann übernehmen die {M}aschinen?},
  author = {Klaus Mainzer},
  year = {2019},
  isbn={978-3-662-58045-5},
  publisher={Springer Berlin, Heidelberg},
  doi = {10.1007/978-3-662-58046-2}
}

@book{Gabriel2020,
  title = {Fiktion},
  author = {Markus Gabriel},
  year = {2020},
  isbn={978-3-518-58748-5},
  publisher={Suhrkamp Verlag},
}

@book{Gabriel2013,
  title = {{W}arum es die {W}elt nicht gibt},
  author = {Markus Gabriel},
  year = {2013},
  isbn={978-3550080104},
  publisher={Ullstein Verlag},
}

@book{Gabriel2018,
  title = {{D}er {S}inn des {D}enkens},
  author = {Markus Gabriel},
  year = {2018},
  isbn={978-3550081934},
  publisher={Ullstein Verlag},
}

@book{Weizenbaum1978,
  author = {Weizenbaum, Joseph},
  title = {{D}ie {M}acht der {C}omputer und die {O}hnmacht der {V}ernunft},
  publisher = {Suhrkamp Verlag},
  isbn = {9783518278741},
  year = {1978},
}

@Article{Buchinger2012,
  author   = {Eva Buchinger},
  journal  = {Constructivist Foundation},
  title    = {{L}uhmann and the constructivist heritage: A critical reflection},
  year     = {2012},
  number   = {1},
  pages    = {19--28},
  volume   = {8},
  file     = {:files/Buchinger2012.pdf:PDF},
  keywords = {luhmann},
  url      = {http://constructivist.info/8/1/019},
}

@Misc{Kappor2024,
  author        = {Sayash Kapoor and Peter Henderson and Arvind Narayanan},
  title         = {Promises and pitfalls of artificial intelligence for legal applications},
  year          = {2024},
  archiveprefix = {arXiv},
  comment       = {Link to the presentation: https://www.lawtech.hk/promises-and-pitfalls-of-artificial-intelligence-for-legal-applications/},
  eprint        = {2402.01656},
  file          = {:files/Kappor2024.pdf:PDF},
  keywords      = {application},
  primaryclass  = {cs.CY},
  url           = {https://arxiv.org/abs/2402.01656},
}

@Misc{Kapoor2024b,
  author        = {Sayash Kapoor and Benedikt Stroebl and Zachary S. Siegel and Nitya Nadgir and Arvind Narayanan},
  title         = {{AI} agents that matter},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2407.01502},
  file          = {:files/Kapoor2024b.pdf:PDF},
  keywords      = {agent},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.01502},
}

@Misc{Kapoor2024c,
  author        = {Sayash Kapoor and Rishi Bommasani and Kevin Klyman and Shayne Longpre and Ashwin Ramaswami and Peter Cihon and Aspen Hopkins and Kevin Bankston and Stella Biderman and Miranda Bogen and Rumman Chowdhury and Alex Engler and Peter Henderson and Yacine Jernite and Seth Lazar and Stefano Maffulli and Alondra Nelson and Joelle Pineau and Aviya Skowron and Dawn Song and Victor Storchan and Daniel Zhang and Daniel E. Ho and Percy Liang and Arvind Narayanan},
  title         = {On the societal impact of open foundation models},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2403.07918},
  file          = {:files/Kapoor2024c.pdf:PDF},
  keywords      = {application},
  primaryclass  = {cs.CY},
  url           = {https://arxiv.org/abs/2403.07918},
}

@InProceedings{Liu2024,
  author    = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
  booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
  title     = {Teaching {CS50} with {AI}: Leveraging generative artificial intelligence in computer science education},
  year      = {2024},
  address   = {New York, NY, USA},
  pages     = {1927},
  publisher = {Association for Computing Machinery},
  series    = {SIGCSE 2024},
  abstract  = {},
  doi       = {10.1145/3626253.3635427},
  file      = {:files/Liu2024.pdf:PDF},
  isbn      = {9798400704246},
  keywords  = {application},
  location  = {Portland, OR, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3626253.3635427},
}

@Misc{Schmidhuber2015,
  author        = {Juergen Schmidhuber},
  title         = {On learning to think: Algorithmic information theory for novel combinations of reinforcement learning controllers and recurrent neural world models},
  year          = {2015},
  archiveprefix = {arXiv},
  eprint        = {1511.09249},
  file          = {:files/Schimdhuber2015.pdf:PDF},
  keywords      = {world model},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/1511.09249},
}

@article{Searle1980,
  title     = {Minds, brains, and programs},
  author    = {Searle, John R.},
  journal   = {Behavioral and Brain Sciences},
  volume    = {3},
  number    = {3},
  pages     = {417--424},
  year      = {1980},
  publisher = {Cambridge University Press},
  doi       = {10.1017/S0140525X00005756}
}

@article{Shanahan2024,
  author = {Shanahan, Murray},
  title = {Talking about large language models},
  year = {2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {67},
  number = {2},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/3624724},
  doi = {10.1145/3624724},
  abstract = {Interacting with a contemporary LLM-based conversational agent can create an illusion of being in the presence of a thinking creature. Yet, in their very nature, such systems are fundamentally not like us.},
  journal = {Communications of the ACM},
  month = {jan},
  pages = {68–79},
  numpages = {12}
}

@Article{Lappin2024,
  author   = {Lappin, Shalom},
  journal  = {Journal of Logic, Language and Information},
  title    = {Assessing the strengths and weaknesses of large language models},
  year     = {2024},
  issn     = {1572-9583},
  number   = {1},
  pages    = {9--20},
  volume   = {33},
  abstract = {},
  doi      = {10.1007/s10849-023-09409-x},
  file     = {:files/Lappin2024.pdf:PDF},
  keywords = {llm},
  refid    = {Lappin2024},
  url      = {https://doi.org/10.1007/s10849-023-09409-x},
}

@Article{Shah2024,
  author     = {Shah, Chirag and Bender, Emily M.},
  journal    = {ACM Trans. Web},
  title      = {Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?},
  year       = {2024},
  issn       = {1559-1131},
  month      = {apr},
  number     = {3},
  volume     = {18},
  abstract   = {},
  address    = {New York, NY, USA},
  articleno  = {33},
  doi        = {10.1145/3649468},
  file       = {:files/Shah2024.pdf:PDF},
  issue_date = {August 2024},
  keywords   = {artificial communication, llm},
  numpages   = {24},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3649468},
}

@Inbook{Murphy2013,
  author="Murphy, Nancey",
  editor="Runehov, Anne L. C.
  and Oviedo, Lluis",
  title="Nonreductive Physicalism",
  bookTitle="Encyclopedia of Sciences and Religions",
  year="2013",
  publisher="Springer Netherlands",
  address="Dordrecht",
  pages="1533--1539",
  isbn="978-1-4020-8265-8",
  doi="10.1007/978-1-4020-8265-8_793",
  url="https://doi.org/10.1007/978-1-4020-8265-8_793"
}


@book{Jaskolla2016,
  address = {New York, NY},
  editor = {Godehard Br\"{u}ntrup and Ludwig Jaskolla},
  publisher = {Oxford University Press USA},
  title = {Panpsychism: Contemporary Perspectives},
  year = {2016}
}


@book{Kim2010,
  author = {Jaegwon Kim},
  title = {Philosophy of Mind},
  editor = {3},
  publisher = {Routledge},
  isbn = {978-0813344584},
  year = {2021},
}

@book{Rosengruen2021,
  author = {Rosengr{\"u}n, Sebastian},
  title = {{H}andbuch der {K}ünstlichen {I}ntelligenz},
  editor = {Günther Görz and Ute Schmid and Tanya Braun},
  publisher = {De Gruyter Oldenbourg},
  address = {Berlin, Boston},
  doi = {10.1515/9783110659948},
  isbn = {9783110659948},
  year = {2021},
}

@book{Goertzel2007,
  title     = {Artificial General Intelligence},
  editor    = {Goertzel, Ben and Pennachin, Cassio},
  year      = {2007},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  series    = {Cognitive Technologies},
  isbn      = {978-3-540-23733-4},
  doi       = {10.1007/978-3-540-68677-4}
}

@book{Misselhorn2023,
  author    = {Catrin Misselhorn},
  title     = {{K}ünstliche {I}ntelligenz – das {E}nde der {K}unst?},
  year      = {2023},
  publisher = {Reclam, Philipp, jun. GmbH, Verlag},
  address   = {Ditzingen, Germany},
  series    = {Reclams Universal-Bibliothek},
  isbn      = {978-3-15-014355-1}
}

@Article{Esposito2017,
  author      = {Elena Esposito},
  journal     = {Zeitschrift für Soziologie},
  title       = {Artificial communication? {T}he production of contingency by algorithms},
  year        = {2017},
  number      = {4},
  pages       = {249--265},
  volume      = {46},
  doi         = {10.1515/zfsoz-2017-1014},
  file        = {:files/Esposito2017.pdf:PDF},
  keywords    = {artificial communication,luhmann},
  lastchecked = {2024-07-25},
}

@Misc{Keenan2024,
  author        = {Bernard Keenan and Kacper Sokol},
  title         = {Mind the gap! Bridging explainable artificial intelligence and human understanding with {L}uhmann's functional theory of communication},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2302.03460},
  file          = {:files/Keenan2024.pdf:PDF},
  keywords      = {artificial communication,luhmann},
  primaryclass  = {cs.CY},
  url           = {https://arxiv.org/abs/2302.03460},
}

@Article{Maurer2010,
  author   = {Kathrin Maurer},
  journal  = {Pandaemonium Germanicum},
  title    = {Communication and language in {N}iklas {L}uhmann's systems-theory},
  year     = {2009},
  doi      = {10.1590/S1982-88372010000200002},
  file     = {:files/Maurer2010.pdf:PDF},
  keywords = {language,luhmann},
}

@Article{Kuenzler1990,
  author   = {Künzler, Jan},
  title    = {{I}nterpenetration bei {P}arsons und {L}uhmann: {V}on der {I}ntegration zur {P}roduktion von {U}nordnung: {P}arsons and {L}uhmann on interpenetration: From integration to the production of disorder},
  year     = {1990},
  abstract = {},
  file     = {:files/Kuenzler1990.pdf:PDF},
  keywords = {language,luhmann},
  url      = {https://nbn-resolving.org/urn:nbn:de:bvb:20-opus-51112},
}

@InProceedings{MacNeil2023,
  author    = {MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj},
  booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
  title     = {The implications of large language models for {CS} teachers and students},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1255},
  publisher = {Association for Computing Machinery},
  series    = {SIGCSE 2023},
  abstract  = {The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
  doi       = {10.1145/3545947.3573358},
  file      = {:files/MacNeil2023.pdf:PDF},
  isbn      = {9781450394338},
  keywords  = {application},
  location  = {Toronto ON, Canada},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3545947.3573358},
}

@Book{Dennett1989,
  author    = {Daniel C. Dennett},
  publisher = {The MIT Press},
  title     = {The Intentional Stance},
  year      = {1989},
  isbn      = {9780262540537},
}

@Article{McCulloch1943,
  author   = {McCulloch, Warren S. and Pitts, Walter},
  journal  = {The bulletin of mathematical biophysics},
  title    = {A logical calculus of the ideas immanent in nervous activity},
  year     = {1943},
  issn     = {1522-9602},
  number   = {4},
  pages    = {115--133},
  volume   = {5},
  abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  doi      = {10.1007/BF02478259},
  refid    = {McCulloch1943},
  url      = {https://doi.org/10.1007/BF02478259},
}


@misc{Grattafiori2024,
      title={The {LLaMA} 3 herd of models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{Touvron2023,
      title={{LLaMA}: Open and efficient foundation language models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

@misc{DeepSeekAI2025,
      title={{D}eep{S}eek-{R1}: Incentivizing reasoning capability in {LLM}s via reinforcement learning}, 
      author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}

@misc{DeepSeekAI2024,
      title={{D}eep{S}eek-{V2}: A strong, economical, and efficient mixture-of-experts language model}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bin Wang and Bingxuan Wang and Bo Liu and Chenggang Zhao and Chengqi Dengr and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Hanwei Xu and Hao Yang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jin Chen and Jingyang Yuan and Junjie Qiu and Junxiao Song and Kai Dong and Kaige Gao and Kang Guan and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruizhe Pan and Runxin Xu and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Size Zheng and T. Wang and Tian Pei and Tian Yuan and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Liu and Xin Xie and Xingkai Yu and Xinnan Song and Xinyi Zhou and Xinyu Yang and Xuan Lu and Xuecheng Su and Y. Wu and Y. K. Li and Y. X. Wei and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Zheng and Yichao Zhang and Yiliang Xiong and Yilong Zhao and Ying He and Ying Tang and Yishi Piao and Yixin Dong and Yixuan Tan and Yiyuan Liu and Yongji Wang and Yongqiang Guo and Yuchen Zhu and Yuduan Wang and Yuheng Zou and Yukun Zha and Yunxian Ma and Yuting Yan and Yuxiang You and Yuxuan Liu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhewen Hao and Zhihong Shao and Zhiniu Wen and Zhipeng Xu and Zhongyu Zhang and Zhuoshu Li and Zihan Wang and Zihui Gu and Zilin Li and Ziwei Xie},
      year={2024},
      eprint={2405.04434},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.04434},
      doi={},
}

@misc{Anthropic2024,
  author   = {Anthropic},
  journal  = {Anthropic blog},
  title    = {The {C}laude 3 model family: {O}pus, {S}onnet, {H}aiku},
  year     = {2019},
}

@misc{Radford2019,
  author   = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal  = {OpenAI blog},
  title    = {Language models are unsupervised multitask learners},
  year     = {2019},
}

@Misc{Kojima2023,
  author        = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
  title         = {Large language models are zero-shot reasoners},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2205.11916},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2205.11916},
}

@book{Dennett1991,
  title     = {Consciousness Explained},
  author    = {Dennett, Daniel C.},
  year      = {1991},
  publisher = {Little, Brown and Company},
  address   = {Boston, MA},
  isbn      = {978-0316180665}
}

@Article{Frankish2016,
  author    = {Keith Frankish},
  journal   = {Journal of Consciousness Studies},
  title     = {Illusionism as a theory of consciousness},
  year      = {2016},
  volume    = {23},
  number = {11-12},
  pages = {11--39},
  publisher = {Imprint Academic},
  url       = {http://keithfrankish.github.io/articles/Frankish_Illusionism%20as%20a%20theory%20of%20consciousness_eprint.pdf},
}


@techreport{McCarthy1955,
  author       = {John McCarthy and Marvin L. Minsky and Nathaniel Rochester and Claude E. Shannon},
  title        = {A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence},
  institution  = {Dartmouth College},
  year         = {1955},
  url          = {https://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html},
  note         = {Accessed: 2025-01-14},
}

@Article{Nagel1974,
  author    = {Thomas Nagel},
  journal   = {Philosophical Review},
  title     = {What is it like to be a bat?},
  year      = {1974},
  number    = {October},
  pages     = {435--50},
  volume    = {83},
  doi       = {10.2307/2183914},
  publisher = {Cambridge University Press},
}

@article{Dennett2016,
  author = {Daniel Dennett},
  journal = {Journal of Consciousness Studies},
  number = {11-12},
  pages = {65--72},
  title = {Illusionism as the Obvious Default Theory of Consciousness},
  volume = {23},
  year = {2016}
}

@book{Floridi2011,
    author = {Floridi, Luciano},
    title = {The Philosophy of Information},
    publisher = {Oxford University Press},
    year = {2011},
    month = {01},
    abstract = {This book brings together the outcome of ten years of research. It is based on a simple project, which was begun towards the end of the 1990s: information is a crucial concept, which deserves a thorough philosophical investigation. So the book lays down the conceptual foundations of a new area of research: the philosophy of information. It does so systematically, by pursuing three goals. The first is metatheoretical. The book describes what the philosophy of information is, its problems, and its method of levels of abstraction. These are the topics of the first part, which comprises chapters one, two and three. The second goal is introductory. In chapters four and five, the book explores the complex and diverse nature of several informational concepts and phenomena. The third goal is constructive. In the remaining ten chapters, the book answers some classic philosophical questions in information-theoretical terms. As a result, the book provides the first, unified and coherent research programme for the philosophy of information, understood as a new, independent area of research, concerned with (1) the critical investigation of the conceptual nature and basic principles of information, including its dynamics, utilization, and sciences; and (2) the elaboration and application of information-theoretic and computational methodologies to philosophical problems.},
    isbn = {9780199232383},
    doi = {10.1093/acprof:oso/9780199232383.001.0001},
    url = {https://doi.org/10.1093/acprof:oso/9780199232383.001.0001},
}




@Inbook{Turing2009,
author="Turing, Alan M.",
editor="Epstein, Robert
and Roberts, Gary
and Beber, Grace",
title="Computing Machinery and Intelligence",
bookTitle="Parsing the Turing test: Philosophical and methodological issues in the quest for the thinking computer",
year="2009",
publisher="Springer Netherlands",
address="Dordrecht",
pages="23--65",
isbn="978-1-4020-6710-5",
doi="10.1007/978-1-4020-6710-5_3",
url="https://doi.org/10.1007/978-1-4020-6710-5_3"
}


@misc{iso2022,
  author       = {{I}nternational {O}rganization for {S}tandardization},
  title        = {What is {AI}?},
  howpublished = {\url{https://www.iso.org/artificial-intelligence/what-is-ai}},
  note         = {Accessed: 2025-01-14},
  organization = {International Organization for Standardization},
  address      = {Geneva, Switzerland},
  year         = {2022},
  number       = {ISO/IEC 22989:2022},
  url          = {https://www.iso.org/standard/74296.html}
}

@book{Russell2021,
  author   = {Russell, Stuart and Norvig, Peter},
  title    = {Artificial Intelligence, Global Edition A Modern Approach},
  abstract = {{The most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence
The long-anticipated revision of Artificial Intelligence: A Modern Approach explores the full breadth and depth of the field of artificial intelligence (AI). 
The 4th Edition brings readers up to date on the latest technologies, present concepts in a more unified manner, and offers new or expanded coverage of 
machine learning, deep learning, transfer learning, multi agent systems, robotics, natural language processing, causality, probabilistic programming, 
privacy, fairness, and safe AI.
}},
  pages    = {1168},
  publisher = {Pearson Deutschland},
  year     = {2021},
  isbn     = {9781292401133},
  doi      = {},
  url      = {https://elibrary.pearson.de/book/99.150005/9781292401171}
}

@book{Bateson1972,
  author    = {Gregory Bateson},
  title     = {Steps to an Ecology of Mind},
  publisher = {Chandler Publishing Company},
  year      = {1972},
  address   = {San Francisco},
  isbn      = {0-226-03905-6}
}

@book{Weizenbaum2001,
  author = {Weizenbaum, Joseph},
  title = {{C}omputermacht und {G}esellschaft},
  editor = {Gunna Wendt and Franz Klug},
  publisher = {Suhrkamp Verlag},
  isbn = {9783518291559},
  year = {2001},
}

@inproceedings{Wei2022,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@misc{Hinton2023,
  author    = {Geoffrey Hinton},
  title     = {Geoffrey Hinton: The Man Who Helped Make {AI}},
  year      = {2023},
  url       = {https://www.youtube.com/watch?v=vxkBE23zDmQ},
  note      = {Interview by CBS News, published on YouTube},
  howpublished = {YouTube Video},
}

@misc{Heidegger1976,
  author    = {Martin Heidegger},
  title     = {``{N}ur noch ein {G}ott kann uns retten.'' {SPIEGEL}-{G}espräch mit {M}artin {H}eidegger},
  journal   = {DER SPIEGEL},
  year      = {1976},
  volume    = {29},
  pages     = {193--219},
  note      = {Zitiert nach S. 209 f.}
}

@book{Moeller2011,
  author = {Hans-Georg M{\"o}ller},
  title ={{T}he {R}adical {L}uhmann}, 
  subtitle = {{I}dentity {A}fter {A}uthenticity},
  year = {2011},
  isbn = {978-0-231-115379-9},
  publisher = {Columbia University Press},
  pages = {184}
}

@Book{Esposito2024,
  author    = {Elena Esposito},
  publisher = {Residenz Verlag},
  title     = {{K}ommunikation mit unverständlichen {M}aschinen},
  year      = {2024},
  isbn      = {13: 978-3-7017-3609-6},
}

@Article{Lovasz2023,
  author    = {Lovasz, Adam},
  journal   = {Kybernetes},
  title     = {{N}iklas {L}uhmann and {J}acques {E}llul on the autonomy of technology},
  year      = {2023},
  issn      = {0368-492X},
  month     = {jan},
  number    = {ahead-of-print},
  volume    = {ahead-of-print},
  abstract  = {Purpose Drawing on the work of Niklas Luhmann, the paper argues that technology can be viewed as a self-referential system which is autonomous from both human beings and other function systems of society. The paper aims to develop a philosophy of technology from the work of Niklas Luhmann. To achieve this aim, it draws upon the systems-theory work of Jacques Ellul, a philosopher of technology who focuses on the autonomous potential of technological evolution. Design/methodology/approach The paper draws on the work of Niklas Luhmann and Jacques Ellul to explore the theme of autonomous technology and what this means for our thinking about technological issues in the twenty-first century. Insights from these two thinkers and researchers working in the Luhmannian sociological tradition are applied to remote work. Findings The sociological approach of Luhmann, coupled with Ellul's insights into the autonomous nature of technology, can help us develop a systems theory of technology which takes seriously its irreducibility to human functions. Research limitations/implications The paper contributes to the growing sociological literature that thematizes the Luhmannian approach to technology, helping us better understand this phenomenon and think in new ways about what technological autonomy means. Originality/value The paper brings together the work of Luhmann, Ellul and contemporary researchers to advance a new understanding of technology and technological communication.},
  doi       = {10.1108/K-02-2023-0287},
  file      = {:files/Lovasz2023.pdf:PDF},
  keywords  = {artificial communication,luhmann},
  publisher = {Emerald Publishing Limited},
  url       = {https://doi.org/10.1108/K-02-2023-0287},
}

@misc{Ziegler2020,
      title={Fine-Tuning language models from human preferences}, 
      author={Daniel M. Ziegler and Nisan Stiennon and Jeffrey Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
      year={2020},
      eprint={1909.08593},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.08593}, 
}

@misc{Assran2023,
      title={Self-supervised learning from images with a joint-embedding predictive architecture}, 
      author={Mahmoud Assran and Quentin Duval and Ishan Misra and Piotr Bojanowski and Pascal Vincent and Michael Rabbat and Yann LeCun and Nicolas Ballas},
      year={2023},
      eprint={2301.08243},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.08243}, 
}

@misc{Schmidhuber2015,
      title={On learning to think: Algorithmic information theory for novel combinations of reinforcement learning controllers and recurrent neural world models}, 
      author={Juergen Schmidhuber},
      year={2015},
      eprint={1511.09249},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1511.09249}, 
}

@misc{Cao2024,
      title={Beyond sparse rewards: Enhancing reinforcement learning with language model critique in text generation}, 
      author={Meng Cao and Lei Shu and Lei Yu and Yun Zhu and Nevan Wichers and Yinxiao Liu and Lei Meng},
      year={2024},
      eprint={2401.07382},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.07382}, 
}

@article{Zhou2021,
    author = {Zhou, Meng and Li, Zechen and Xie, Pengtao},
    title = {Self-supervised regularization for text classification},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {9},
    pages = {641-656},
    year = {2021},
    month = {07},
    abstract = {Text classification is a widely studied problem and has broad applications. In
                    many real-world problems, the number of texts for training classification models
                    is limited, which renders these models prone to overfitting. To address this
                    problem, we propose SSL-Reg, a data-dependent regularization approach based on
                    self-supervised learning (SSL). SSL (Devlin et al., 2019a) is an unsupervised learning approach that
                    defines auxiliary tasks on input data without using any human-provided labels
                    and learns data representations by solving these auxiliary tasks. In SSL-Reg, a
                    supervised classification task and an unsupervised SSL task are performed
                    simultaneously. The SSL task is unsupervised, which is defined purely on input
                    texts without using any human- provided labels. Training a model using an SSL
                    task can prevent the model from being overfitted to a limited number of class
                    labels in the classification task. Experiments on 17 text classification
                    datasets demonstrate the effectiveness of our proposed method. Code is available
                    at https://github.com/UCSD-AI4H/SSReg.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00389},
    url = {https://doi.org/10.1162/tacl\_a\_00389},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00389/1930826/tacl\_a\_00389.pdf},
}


@article{Turing1937,
author = {Turing, A. M.},
title = {On computable numbers, with an application to the {E}ntscheidungsproblem},
journal = {Proceedings of the London Mathematical Society},
volume = {s2-42},
number = {1},
pages = {230--265},
doi = {https://doi.org/10.1112/plms/s2-42.1.230},
url = {https://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230},
eprint = {https://londmathsoc.onlinelibrary.wiley.com/doi/pdf/10.1112/plms/s2-42.1.230},
year = {1937}
}



@book{Luhmann1998,
  year = {1998},
  author = {Niklas Luhmann},
  title = {{D}ie {G}esellschaft der {G}esellschaft},
  publisher = {Suhrkamp Verlag},
  address = {Frankfurt/M.},
  isbn = {978-3-518-28960-0}
}

@book{Luhmann1997,
  year = {1997},
  author = {Niklas Luhmann},
  title = {{D}ie {K}unst der {G}esellschaft},
  publisher = {Suhrkamp Verlag},
  address = {Frankfurt/M.},
  isbn = {978-3-518-28903-7}
}

@book{Luhmann2013,
  year = {1987},
  author = {Niklas Luhmann},
  title = {Introduction to Systems Theory},
  publisher = {Cambridge; Malden},
  editor = {Dirk Baecker}
}


@book{Maturana1987,
  year = {1987},
  author = {Huberto R. Maturana and Francisco J. Varela},
  title = {{D}er {B}aum der {E}rkenntnis},
  publisher = {Scherz: Bern}
}

@article{Luhmann1988,
  author = {Niklas Luhmann},
  keywords = {},
  journal = {Benteli},
  address = {Bern},
  title = {{E}rkenntnis als {K}onstruktion},
  year = {1988},
  pages = {7--55},
}


@article{Shannon1948,
  author = {Shannon, Claude E.},
  journal = {Bell Syst. Tech. J.},
  number = {3},
  pages = {379-423},
  title = {A mathematical theory of communication},
  volume = {27},
  year = {1948}
}

@book{Kant1781,
  author = {Kant, Immanuel},
  title = {{K}ritik der reinen {V}ernunft},
  year = {1781},
}

@misc{Luhmann1995,
  author = {Niklas Luhmann},
  institution = {London School of Economics and Political Science},
  howpublished = {University lecture},
  year = {1995},
  title = {Systems theory and postmodernism},
  url = {https://www.youtube.com/watch?v=wBBAkh52GhA}
}

@book{Nassehi2019,
  author = {Armin Nassehi},
  title = {Muster},
  subtitle = {{T}heorie der digitalen {G}esellschaft},
  publisher = {C.H.Beck},
  isbn = {978-3406740244},
  year = {2019},
  pages = {352},
}

@Inbook{Esposito1997,
author="Esposito, Elena",
editor="Hijikata, Toru
and Nassehi, Armin",
title="{R}isiko und {C}omputer: {D}as {P}roblem der {K}ontrolle des {M}angels der {K}ontrolle",
bookTitle="Riskante Strategien: Beitr{\"a}ge zur Soziologie des Risikos",
year="1997",
publisher="VS Verlag f{\"u}r Sozialwissenschaften",
address="Wiesbaden",
pages="93--108",
abstract="Die Ph{\"a}nomene Risiko und Computer haben, aus soziologischer Perspektive gesehen, eine Gemeinsamkeit: Beide verweisen auf das Problem der Kontrolle, oder genauer: auf die Notwendigkeit, den Begriff von Kontrolle neu zu formulieren. Im folgenden werde ich diese Gemeinsamkeit genauer analysieren und versuche mich an einer Neuformulierung des Kontrollbegriffs.",
isbn="978-3-322-85107-9",
doi="10.1007/978-3-322-85107-9_5",
url="https://doi.org/10.1007/978-3-322-85107-9_5"
}



@article{Turing1950,
    author = {Turing, A. M.},
    title = {I.--{C}OMPUTING MACHINERY AND INTELLIGENCE},
    journal = {Mind},
    volume = {LIX},
    number = {236},
    pages = {433-460},
    year = {1950},
    month = {10},
    issn = {0026-4423},
    doi = {10.1093/mind/LIX.236.433},
    url = {https://doi.org/10.1093/mind/LIX.236.433},
    eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/61209000/mind\_lix\_236\_433.pdf},
}


@book{Heidegger1977,
  address = {New York},
  author = {Martin Heidegger},
  editor = {},
  publisher = {Harper \& Row},
  title = {The Question Concerning Technology, and Other Essays},
  year = {1977}
}


@misc{Casper2023,
      title={Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback}, 
      author={Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and Jérémy Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Wang and Samuel Marks and Charbel-Raphaël Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J. Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem Bıyık and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell},
      year={2023},
      eprint={2307.15217},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2307.15217}, 
}

@article{Chalmers1995,
  author = {David Chalmers},
  journal = {Journal of Consciousness Studies},
  number = {3},
  pages = {200--19},
  publisher = {Imprint Academic},
  title = {Facing Up to the Problem of Consciousness},
  volume = {2},
  year = {1995}
}


@Misc{Bubeck2023,
  author        = {S{e}bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  title         = {Sparks of artificial general intelligence: Early experiments with {GPT-4}},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.12712},
  file          = {:files/bubeck2023.pdf:PDF},
  keywords      = {fundamentals},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.12712},
}

@Book{Wittgenstein1953,
  author = {Ludwig Wittgenstein},
  title = {{P}hilosophische {U}ntersuchungen},
  year = {1953},
}

@misc{Piantadosi2022,
      title={Meaning without reference in large language models}, 
      author={Steven T. Piantadosi and Felix Hill},
      year={2022},
      eprint={2208.02957},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2208.02957}, 
}

@article{Hinton1989,
title = {Connectionist learning procedures},
journal = {Artificial Intelligence},
volume = {40},
number = {1},
pages = {185--234},
year = {1989},
issn = {0004-3702},
doi = {10.1016/0004-3702(89)90049-0},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900490},
author = {Geoffrey E. Hinton},
abstract = {A major goal of research on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths in such a way that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting gradient-descent procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, gradient-descent learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks.}
}

@misc{McKenzie2024,
      title={Consciousness defined: Requirements for biological and artificial general intelligence}, 
      author={Craig I. McKenzie},
      year={2024},
      eprint={2406.01648},
      archivePrefix={arXiv},
      primaryClass={q-bio.NC},
      url={https://arxiv.org/abs/2406.01648},
      doi={10.48550/arXiv.2406.01648}
}

@misc{Juliani2022,
      title={On the link between conscious function and general intelligence in humans and machines}, 
      author={Arthur Juliani and Kai Arulkumaran and Shuntaro Sasai and Ryota Kanai},
      year={2022},
      eprint={2204.05133},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2204.05133}, 
}

@article{Chalmers2023,
  author    = {David J. Chalmers},
  title     = {Could a Large Language Model Be Conscious?},
  journal   = {Boston Review},
  year      = {2023},
  url       = {https://www.bostonreview.net/articles/could-a-large-language-model-be-conscious/}
}

@article{Manning2020,
author = {Christopher D. Manning  and Kevin Clark  and John Hewitt  and Urvashi Khandelwal  and Omer Levy },
title = {Emergent linguistic structure in artificial neural networks trained by self-supervision},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {48},
pages = {30046-30054},
year = {2020},
doi = {10.1073/pnas.1907367117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1907367117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907367117},
abstract = {This paper explores the knowledge of linguistic structure learned by large artificial neural networks, trained via self-supervision, whereby the model simply tries to predict a masked word in a given context. Human language communication is via sequences of words, but language understanding requires constructing rich hierarchical structures that are never observed explicitly. The mechanisms for this have been a prime mystery of human language acquisition, while engineering work has mainly proceeded by supervised learning on treebanks of sentences hand labeled for this latent structure. However, we demonstrate that modern deep contextual language models learn major aspects of this structure, without any explicit supervision. We develop methods for identifying linguistic hierarchical structure emergent in artificial neural networks and demonstrate that components in these models focus on syntactic grammatical relationships and anaphoric coreference. Indeed, we show that a linear transformation of learned embeddings in these models captures parse tree distances to a surprising degree, allowing approximate reconstruction of the sentence tree structures normally assumed by linguists. These results help explain why these models have brought such large improvements across many language-understanding tasks.}
}

@InProceedings{Bender2020,
  author    = {Bender, Emily M. and Koller, Alexander},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Climbing towards {NLU}: {On} meaning, form, and understanding in the age of data},
  year      = {2020},
  address   = {Online},
  month     = {jul},
  pages     = {5185--5198},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2020.acl-main.463},
  file      = {:files/Bender2020.pdf:PDF},
}

@InProceedings{Bender2021,
  author    = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  title     = {On the dangers of stochastic parrots: Can language models be too big?},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {610–623},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '21},
  abstract  = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  doi       = {10.1145/3442188.3445922},
  file      = {:files/Bender2021.pdf:PDF},
  isbn      = {9781450383097},
  location  = {Virtual Event, Canada},
  numpages  = {14},
}

@Article{Caluori2024,
  author   = {Caluori, Lucas},
  journal  = {AI {\&} SOCIETY},
  title    = {Hey {A}lexa, why are you called intelligent? {A}n empirical investigation on definitions of {AI}},
  year     = {2024},
  issn     = {1435-5655},
  number   = {4},
  pages    = {1905--1919},
  volume   = {39},
  abstract = {This paper seeks to examine the questions of what criteria definitions of Artificial Intelligence (AI) use to define AI, what the disagreements that revolve around the term AI are based on, and what correlations can be drawn to other parameters. Framed as a problem of classification, a random sample of 45 definitions from various text sources was subjected to a qualitative content analysis. The criteria found are concluded in five dimensions, namely (1) learning ability, (2) human likeness, (3) state of “mind”, (4) complexity of the problem, and (5) successfulness. Further, the results support the view that there is no consensus neither on which of these criteria are crucial to define AI nor on how these criteria must be fulfilled. By opposing the frequencies of the dimensions found with the metadata collected, it can be seen that most of these, e.g., country, scientific field, or gender of the author, are statistically independent of content variables, while the medium in which the definition was published shows a strong correlation. Since different mediums target different purposes and different readers, it must be taken into account that writing a definition of AI is to be seen in the context of its distribution area and its goal.},
  doi      = {10.1007/s00146-023-01643-y},
  file     = {:files/Caluori2024.pdf:PDF},
  refid    = {Caluori2024},
  url      = {https://doi.org/10.1007/s00146-023-01643-y},
}

@InCollection{Sheikh2023,
  author    = {Sheikh, Haroon and Prins, Corien and Schrijvers, Erik and Sheikh, Haroon and Prins, Corien and Schrijvers, Erik},
  booktitle = {Mission AI: The New System Technology},
  publisher = {Springer International Publishing},
  title     = {Artificial Intelligence: Definition and Background},
  year      = {2023},
  address   = {Cham},
  pages     = {15--41},
  abstract  = {If we want to embed AI in society, we need to understand what it is. What do we mean by artificial intelligence? How has the technology developed? Where do we stand now?},
  doi       = {10.1007/978-3-031-21448-6_2},
  file      = {:files/Sheikh2023.pdf:PDF},
  issn      = {978-3-031-21448-6},
  refid     = {Sheikh2023},
  url       = {https://doi.org/10.1007/978-3-031-21448-6_2},
}

@Article{Watson2024,
  author    = {Watson, Steven and Romic, Jonathan},
  journal   = {European Educational Research Journal},
  title     = {{ChatGPT} and the entangled evolution of society, education, and technology: A systems theory perspective},
  year      = {2024},
  issn      = {1474-9041},
  month     = {jan},
  abstract  = {This paper presents a novel contribution to the discourse surrounding Large Language Models (LLMs) like ChatGPT in relation to education and society by using systems theory. We argue that ChatGPT can be understood not just as an ?artificial? intelligence but that it is entangled in the evolution of society and therefore education. ChatGPT is a subsystem of the autopoietic system of technology, which in modern society mediates between individual thinking, the physical world, and between thought and society. It is an instrumental tool and a semantic communication medium. With this bimodal framing, we consider ChatGPT and its role in society and education and consider the uses and implications of the technology. In this we respond to the need to introduce a scientific understanding of ChatGPT. We consider its emerging role in promoting educational inclusion, while also reflecting on challenges and limitations. We conclude by identifying the critical multi-dimensional skill sets required for individuals in a ChatGPT-integrated society and calls for strategic educational policies to facilitate this integration responsibly. Overall, this study paves the way for further research by providing a foundational understanding of LLMs through systems theory, thereby informing their ethical and effective incorporation into education.},
  doi       = {10.1177/14749041231221266},
  file      = {:files/Watsonhttps2024.pdf:PDF},
  publisher = {SAGE Publications},
}

@Article{Luhmann1990,
  author    = {Luhmann, Niklas},
  journal   = {Industrial Crisis Quarterly},
  title     = {Technology, environment and social risk: {A} systems perspective},
  year      = {1990},
  issn      = {09218106},
  number    = {3},
  pages     = {223--231},
  volume    = {4},
  abstract  = {[The paper pleads for conceptual changes in the ways we describe modern society. We may use the same words, but should replace the antonyms or redefine their contexts. Technology can be conceived of as being not primarily a proven relation of cause and effect, but rather as a simplification within a causal context, a simplification that has its own consequences. Risk is not simply the lack of safety, but rather the possible damage that may result from one's own decisions. The antonym of risk, then, would be danger as possible damage stemming from external sources. Steering (or public policy) can be conceived as generating differences in order to minimize other differences, rather than controlling the state of the system.]},
  database  = {JSTOR},
  publisher = {Sage Publications, Inc.},
  url       = {http://www.jstor.org/stable/26162777},
}

@Article{Soegaard2023,
  author   = {Søgaard, Anders},
  journal  = {Minds and Machines},
  title    = {Grounding the vector space of an octopus: Word meaning from raw text},
  year     = {2023},
  issn     = {1572-8641},
  number   = {1},
  pages    = {33--54},
  volume   = {33},
  abstract = {Most, if not all, philosophers agree that computers cannot learn what words refers to from raw text alone. While many attacked Searle’s Chinese Room thought experiment, no one seemed to question this most basic assumption. For how can computers learn something that is not in the data? Emily Bender and Alexander Koller (2020) recently presented a related thought experiment--the so-called Octopus thought experiment, which replaces the rule-based interlocutor of Searle’s thought experiment with a neural language model. The Octopus thought experiment was awarded a best paper prize and was widely debated in the AI community. Again, however, even its fiercest opponents accepted the premise that what a word refers to cannot be induced in the absence of direct supervision. I will argue that what a word refers to is probably learnable from raw text alone. Here’s why: higher-order concept co-occurrence statistics are stable across languages and across modalities, because language use (universally) reflects the world we live in (which is relatively stable). Such statistics are sufficient to establish what words refer to. My conjecture is supported by a literature survey, a thought experiment, and an actual experiment.},
  doi      = {10.1007/s11023-023-09622-4},
  file     = {:files/Sogaard2023.pdf:PDF},
  refid    = {Søgaard2023},
  url      = {https://doi.org/10.1007/s11023-023-09622-4},
}

@Article{Reichel2011,
  author  = {André Reichel},
  journal = {Interna-tional Journal of Innovation and Sustainable Development},
  title   = {Technology as system: {T}owards an autopoietic theory of technology,},
  year    = {2011},
  issn    = {105--118},
  volume  = {5},
}

@Article{Sahlgren2021,
  author  = {Sahlgren, Magnus and Carlsson, Fredrik},
  journal = {Frontiers in Artificial Intelligence},
  title   = {The singleton fallacy: Why current critiques of language models miss the point},
  year    = {2021},
  issn    = {2624-8212},
  volume  = {4},
  doi     = {10.3389/frai.2021.682578},
  file    = {:files/Sahlgren2021.pdf:PDF},
  url     = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2021.682578},
}

@inproceedings{Nass1994,
author = {Nass, Clifford and Steuer, Jonathan and Tauber, Ellen R.},
title = {Computers are social actors},
year = {1994},
isbn = {0897916506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191666.191703},
doi = {10.1145/191666.191703},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {72–78},
numpages = {7},
keywords = {agents, anthropomorphism, gender, social psychology, speech, voice},
location = {Boston, Massachusetts, USA},
series = {CHI '94}
}

@Article{Jacobs2022,
  author   = {Jacobs, Oliver L. and Gazzaz, Kamel and Kingstone, Alan},
  journal  = {International Journal of Social Robotics},
  title    = {Mind the robot! {V}ariation in attributions of mind to a wide set of real and fictional robots},
  year     = {2022},
  issn     = {1875-4805},
  number   = {2},
  pages    = {529--537},
  volume   = {14},
  abstract = {The rapid rise of computing power has prompted the desire to develop more social, human-like robots. Quantitatively comparing different computing systems on their ability to simulate human qualities has been a major technical challenge. A recent framework put forth by Gray et al. (Science 315(5812):619, 2007. https://doi.org/10.1126/science.1134475) provides promise as a new means for comparing robots. While the framework has been validated for assessing individual robots with different descriptions, or different behaviours, the framework has not been applied to a wider landscape of robots and machines situated amongst other characters. The present study sought to investigate attributions of mind towards a wide range of real and fictional robots. We asked participants to rate the agency (the ability “to do”) and experience (the ability “to feel”) of 24 characters made up of humans, robots, inanimate objects, and animals. Although robots were collectively rated lower than humans on agency and experience, there was significant variation among robots--even when fictional robots were omitted. The results of this investigation suggest that building robots that are perceived to feel is a fruitful avenue for future development as people are more open to perceiving aspects of mind in a wider range of robots than previously established. Our results also indicate that age is a critical factor in people’s attributions of mind to robots, suggesting that there may be a generational shift towards greater acceptance of robots’ ability to both do and feel.},
  doi      = {10.1007/s12369-021-00807-4},
  refid    = {Jacobs2022},
  url      = {https://doi.org/10.1007/s12369-021-00807-4},
}

@Article{Colom2010,
  author  = {Colom, Roberto and Karama, Sherif and Jung, Rex E. and Haier, Richard J.},
  journal = {Dialogues in clinical neuroscience},
  title   = {Human intelligence and brain networks.},
  year    = {2010},
  pages   = {489--501},
  volume  = {12},
  address = {England},
  doi     = {10.31887/DCNS.2010.12.4/rcolom},
  issue   = {4},
}

@article{Tononi2015,
  author = {Giulio Tononi and Christof Koch},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1668},
  publisher = {Royal Society},
  title = {Consciousness: Here, there and everywhere?},
  volume = {370},
  year = {2015}
}

@inproceedings{Kenneth2023,
title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
author={Kenneth Li and Aspen K Hopkins and David Bau and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=DeG07_TcZvT}
}

@article{Hopfield1982,
  author = {J J Hopfield},
  title = {Neural networks and physical systems with emergent collective computational abilities},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {79},
  number = {8},
  pages = {2554-2558},
  year = {1982},
  doi = {10.1073/pnas.79.8.2554},
}

@Article{McCulloch1943,
  author   = {McCulloch, Warren S. and Pitts, Walter},
  journal  = {The bulletin of mathematical biophysics},
  title    = {A logical calculus of the ideas immanent in nervous activity},
  year     = {1943},
  issn     = {1522-9602},
  number   = {4},
  pages    = {115--133},
  volume   = {5},
  abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  doi      = {10.1007/BF02478259},
  refid    = {McCulloch1943},
  url      = {https://doi.org/10.1007/BF02478259},
}

@Comment{jabref-meta: databaseType:bibtex;}
